{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84c76d9-7707-494c-be3a-34f7772b6e4d",
   "metadata": {},
   "source": [
    "# 1. Carregar o dataset e explorar a estrutura do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5bc9b3-157a-4b72-8ba2-439b32996dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# carregar o dataframe, embaralhar os dados, resetar os index e remover coluna \"Unnamed\" inútil\n",
    "df_news_70k = (\n",
    "    pd.read_csv('../dataset/WELFake_Dataset.csv')\n",
    "    .sample(frac=1)\n",
    "    .reset_index(drop=True)\n",
    "    .drop(\"Unnamed: 0\", axis=\"columns\")\n",
    ")\n",
    "\n",
    "# mostra as primeiras 5 linhas do df\n",
    "print(\"Primeiras 5 linhas do dataframe:\")\n",
    "print(df_news_70k.head())\n",
    "\n",
    "# mostra a quantidade de linhas e colunas\n",
    "print(f\"\\nQuantidade de linhas x colunas: {df_news_70k.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f65a7d-bc22-41cc-888a-61e8cacc6055",
   "metadata": {},
   "source": [
    "# 2. Pré processamento: remover nulos, criar amostras menores e preprocessar os textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccc9ed3-cc94-4e46-b3f4-8ad4f985ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra informações do dataframe\n",
    "print(\"Informações sobre os tipos de dados e quantidades de nulos:\")\n",
    "df_news_70k.info()\n",
    "\n",
    "# apaga as linhas que tem \"title\" ou \"text\" nulos, \n",
    "df_news_70k.dropna(subset=[\"title\", \"text\"], inplace=True) # implace ao invés de retornar um novo dataframe ele altera o original direto\n",
    "\n",
    "print(\"\\nApós apagar os nulos:\")\n",
    "df_news_70k.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d589b83d-3842-4446-ba34-405071dff209",
   "metadata": {},
   "source": [
    "# verificar distribuição entre notícias reais e falsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ddca6-0ab9-4825-abd0-3757f6c50882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nContagem de labels após remover nulos  (1 = real, 0 = fake):\")\n",
    "print(df_news_70k['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce87f7-02bc-4144-b268-e5153ce57c4a",
   "metadata": {},
   "source": [
    "# criar dataframes com tamanho reduzido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2453cd7-cc47-4b83-8d5d-4eb86e6e9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news_1k = df_news_70k[:1000].copy()\n",
    "df_news_10k = df_news_70k[:10000].copy()\n",
    "df_news_20k = df_news_70k[:20000].copy()\n",
    "df_news_30k = df_news_70k[:30000].copy()\n",
    "df_news_40k = df_news_70k[:40000].copy()\n",
    "df_news_50k = df_news_70k[:50000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0efedbc-343f-4990-9af0-528447015f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolher o dataframe que será utilizado abaixo\n",
    "df = df_news_1k.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab7c6d-c18e-4838-a455-d47e5a5c2f5f",
   "metadata": {},
   "source": [
    "# pré processamento do texto\n",
    "\n",
    "passo a passo:\n",
    "1. Converter o texto para minúsculas\n",
    "2. Remover pontuação e dígitos\n",
    "3. Remover palavras irrelevantes como artigos e pronomes(stop words)\n",
    "4. Aplicar Stemming (remover o sufixo das palavaras exemplo \"mudando\" \"mudaria\" para \"mud\") ou lemmatizing (mais sofisticado reduz a palavra para a forma base \"mudaria\" ou \"mudado\" viraria mudar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2cddfd-8125-4bb5-b410-9443a29be50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\") # remove as pontuações\n",
    "nltk.download(\"stopwords\") # remove as stop words \n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # letras minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove a pontuação e os digitos\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
    "\n",
    "    # tokeniza o texto\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # remover as stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # aplicar lemmatizer nas palavras\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "   \n",
    "    # junta as palavras de volta numa string\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb42eac-a06c-498f-9a9f-548b268bdff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb84181-4d00-4ef4-87f0-d80f92ac4499",
   "metadata": {},
   "source": [
    "# 3. Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ca45d-85c2-45c3-987a-2ff2837241f0",
   "metadata": {},
   "source": [
    "## **CountVectorizer = BOW (Bag of Words)**\n",
    "\n",
    "**X** = Matriz onde:\n",
    "- Cada linha = uma notícia\n",
    "- Cada coluna = uma palavra do vocabulário total\n",
    "- Os valores = quantas vezes cada palavra aparece\n",
    "\n",
    "**y** = Vetor simples com as classificações:\n",
    "- [1, 0, 1, 0, 1, ...] onde 1 = real, 0 = fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f047cdb-4a08-4ae7-a858-9b28fbc7bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_classic = CountVectorizer()  # Cria o \"transformador\" BOW para os algoritmos clássicos\n",
    "X_classic = vectorizer_classic.fit_transform(df['text_clean'])  # Aplica BOW nos textos para os algoritmos clássicos\n",
    "\n",
    "vectorizer_quantum = CountVectorizer(max_features = 12)  # Cria o \"transformador\" BOW para os algoritmos quânticos\n",
    "X_quantum = vectorizer_quantum.fit_transform(df['text_clean'])  # Aplica BOW nos textos para os algoritmos quânticos\n",
    "\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f585b-9c20-4621-a35b-9a4a52ed480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_classic, X_test_classic, y_train, y_test = train_test_split(X_classic, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_quantum, X_test_quantum, y_train, y_test = train_test_split(X_quantum, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d22dca-9567-4174-883f-99e6ba5aa38c",
   "metadata": {},
   "source": [
    "# treinar o modelo de regressão linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fe379-1623-4e1b-92b7-b33d7a82c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lcr = LogisticRegression(random_state=42, max_iter=200)\n",
    "lcr.fit(X_train_classic, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f6c7a-7471-42e1-8fc2-69b767420810",
   "metadata": {},
   "source": [
    "# treinar o modelo de árvores aleatórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0db03-016d-4b87-959a-457ec1df97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_classic, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cffe5-06e6-4984-bf1d-0b3fc4cb3fb8",
   "metadata": {},
   "source": [
    "# treinar o modelo com Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9daaf97-e838-48b3-a43f-01a8209a080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "svm.fit(X_train_classic, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7193f4c-d5a1-4a4f-b220-ad04b0de4640",
   "metadata": {},
   "source": [
    "# 4. Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0868a-f48f-45da-8a31-ecdbd77e67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred_lcr = lcr.predict(X_test_classic)\n",
    "y_pred_rfc = rfc.predict(X_test_classic)\n",
    "y_pred_svm = svm.predict(X_test_classic)\n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1 Score:', f1, \"\\n\")\n",
    "\n",
    "print(\"Regressão Logística\")\n",
    "evaluate_model(y_test, y_pred_lcr)\n",
    "\n",
    "print(\"Floresta Aleatória\")\n",
    "evaluate_model(y_test, y_pred_rfc)\n",
    "\n",
    "print(\"Support Vector Classifier \")\n",
    "evaluate_model(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb9e48-a1e4-41db-a399-06c588b2350e",
   "metadata": {},
   "source": [
    "# 5. treinar o modelo quântico usando a biblioteca qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680956da-80dd-4c0c-a146-523150c23537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "\n",
    "num_features = X_quantum.shape[1]\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bbc49-6596-483e-93e8-f351924c694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import RealAmplitudes\n",
    "\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58ae48-7039-48f8-9170-5f2c2aec773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.optimizers import COBYLA\n",
    "\n",
    "optimizer = COBYLA(maxiter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725bc59-e7ee-405f-a972-c2ca63ed3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.primitives import StatevectorSampler as Sampler\n",
    "\n",
    "sampler = Sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4d9f1-8242-4839-ab25-5efd6c7d5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "\n",
    "vqc = VQC(\n",
    "    sampler=sampler,\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer,\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "vqc.fit(X_train_quantum, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Training time: {round(elapsed)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bcfd3d-29f4-4ea2-b974-78307ea27d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões com o modelo quântico\n",
    "y_pred_vqc = vqc.predict(X_test_quantum)\n",
    "\n",
    "# Avaliar o modelo quântico\n",
    "print(\"Variational Quantum Classifier\")\n",
    "evaluate_model(y_test, y_pred_vqc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
