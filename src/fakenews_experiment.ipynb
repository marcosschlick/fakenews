{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84c76d9-7707-494c-be3a-34f7772b6e4d",
   "metadata": {},
   "source": [
    "# 1. Carregar o dataset e explorar a estrutura do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5bc9b3-157a-4b72-8ba2-439b32996dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# carregar o dataframe, embaralhar os dados, resetar os index e remover coluna \"Unnamed\" inútil\n",
    "dataframe = (\n",
    "    pd.read_csv('../dataset/WELFake_Dataset.csv')\n",
    "    .sample(frac=1)\n",
    "    .reset_index(drop=True)\n",
    "    .drop(\"Unnamed: 0\", axis=\"columns\")\n",
    ")\n",
    "\n",
    "# mostra as primeiras 5 linhas do df\n",
    "print(\"Primeiras 5 linhas do dataframe:\")\n",
    "print(dataframe.head())\n",
    "\n",
    "# mostra a quantidade de linhas e colunas\n",
    "print(f\"\\nQuantidade de linhas x colunas: {dataframe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f65a7d-bc22-41cc-888a-61e8cacc6055",
   "metadata": {},
   "source": [
    "# 2. Pré processamento: remover nulos, criar amostras menores e preprocessar os textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccc9ed3-cc94-4e46-b3f4-8ad4f985ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra informações do dataframe\n",
    "print(\"Informações sobre os tipos de dados e quantidades de nulos:\")\n",
    "dataframe.info()\n",
    "\n",
    "# apaga as linhas que tem \"title\" ou \"text\" nulos, \n",
    "dataframe.dropna(subset=[\"title\", \"text\"], inplace=True) # implace ao invés de retornar um novo dataframe ele altera o original direto\n",
    "\n",
    "print(\"\\nApós apagar os nulos:\")\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d589b83d-3842-4446-ba34-405071dff209",
   "metadata": {},
   "source": [
    "# verificar distribuição entre notícias reais e falsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ddca6-0ab9-4825-abd0-3757f6c50882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nContagem de labels após remover nulos  (1 = real, 0 = fake):\")\n",
    "print(dataframe['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce87f7-02bc-4144-b268-e5153ce57c4a",
   "metadata": {},
   "source": [
    "# criar dataframes com tamanho reduzido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2453cd7-cc47-4b83-8d5d-4eb86e6e9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0k = dataframe[:100].copy()\n",
    "df_1k = dataframe[:1000].copy()\n",
    "df_10k = dataframe[:10000].copy()\n",
    "df_30k = dataframe[:30000].copy()\n",
    "df_50k = dataframe[:50000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0efedbc-343f-4990-9af0-528447015f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolher o dataframe que será utilizado para o modelo clássico e para o modelo quântico\n",
    "df_classic = df_1k.copy()\n",
    "df_quantum = df_0k.copy()\n",
    "\n",
    "print(\"\\nContagem de fake news no df clássico (1 = real, 0 = fake):\")\n",
    "print(df_classic['label'].value_counts())\n",
    "\n",
    "print(\"\\nContagem de fake news no df quântico (1 = real, 0 = fake):\")\n",
    "print(df_quantum['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab7c6d-c18e-4838-a455-d47e5a5c2f5f",
   "metadata": {},
   "source": [
    "# pré processamento do texto\n",
    "\n",
    "passo a passo:\n",
    "1. Converter o texto para minúsculas\n",
    "2. Remover pontuação e dígitos\n",
    "3. Remover palavras irrelevantes como artigos e pronomes(stop words)\n",
    "4. Aplicar Stemming (remover o sufixo das palavaras exemplo \"mudando\" \"mudaria\" para \"mud\") ou lemmatizing (mais sofisticado reduz a palavra para a forma base \"mudaria\" ou \"mudado\" viraria mudar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2cddfd-8125-4bb5-b410-9443a29be50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\") # remove as pontuações\n",
    "nltk.download(\"stopwords\") # remove as stop words \n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # letras minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove a pontuação e os digitos\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
    "\n",
    "    # tokeniza o texto\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # remover as stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # aplicar lemmatizer nas palavras\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "   \n",
    "    # junta as palavras de volta numa string\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb42eac-a06c-498f-9a9f-548b268bdff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicar pré processamentos nos dataframes\n",
    "df_classic['text_clean'] = df_classic['text'].apply(preprocess_text)\n",
    "df_quantum['text_clean'] = df_quantum['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb84181-4d00-4ef4-87f0-d80f92ac4499",
   "metadata": {},
   "source": [
    "# 3. Treinamento dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f047cdb-4a08-4ae7-a858-9b28fbc7bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer_classic = CountVectorizer()  # Cria o \"transformador\" BOW para os algoritmos clássicos\n",
    "# X_classic = vectorizer_classic.fit_transform(df['text_clean'])  # Aplica BOW nos textos para os algoritmos clássicos\n",
    "# vectorizer_quantum = CountVectorizer(max_features = 12)  # Cria o \"transformador\" BOW para os algoritmos quânticos\n",
    "# X_quantum = vectorizer_quantum.fit_transform(df['text_clean'])  # Aplica BOW nos textos para os algoritmos quânticos\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# definir o y (varíavel alvo) para cada um dos modelos\n",
    "y_classic = df_classic['label'].values\n",
    "y_quantum = df_quantum['label'].values\n",
    "\n",
    "vectorizer_classic = TfidfVectorizer()  # Cria o \"transformador\" TF-IDF para os algoritmos clássicos\n",
    "X_classic = vectorizer_classic.fit_transform(df_classic['text_clean'])  # Aplica TF-IDF nos textos para os algoritmos clássicos\n",
    "X_quantum = vectorizer_classic.fit_transform(df_quantum['text_clean'])  # Aplica TF-IDF nos textos para os algoritmos quânticos\n",
    "\n",
    "# vectorizer_quantum = TfidfVectorizer(max_features = 12)  # Cria o \"transformador\" TF-IDF para os algoritmos quânticos\n",
    "# X_quantum = vectorizer_quantum.fit_transform(df['text_clean'])  # Aplica TF-IDF nos textos para os algoritmos quânticos\n",
    "\n",
    "lasso_selector = SelectFromModel(\n",
    "    LogisticRegression(random_state=42),\n",
    "    max_features=12\n",
    ")\n",
    "\n",
    "X_quantum = lasso_selector.fit_transform(X_quantum, y_quantum)\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_quantum_scaled = scaler.fit_transform(X_quantum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f585b-9c20-4621-a35b-9a4a52ed480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_classic, X_test_classic, y_train_classic, y_test_classic = train_test_split(X_classic, y_classic, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_quantum, X_test_quantum, y_train_quantum, y_test_quantum = train_test_split(X_quantum_scaled, y_quantum, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d22dca-9567-4174-883f-99e6ba5aa38c",
   "metadata": {},
   "source": [
    "## 3.1 Treinamento dos modelos clássicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be148190-e393-4063-b477-cd3b9c84b80b",
   "metadata": {},
   "source": [
    "### 3.1.1 Treinamento com Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fe379-1623-4e1b-92b7-b33d7a82c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import time\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=200)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train_classic, y_train_classic)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Training time: {round(elapsed)} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f6c7a-7471-42e1-8fc2-69b767420810",
   "metadata": {},
   "source": [
    "### 3.1.2 Treinamento com Árvores Aleatórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0db03-016d-4b87-959a-457ec1df97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import time\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train_classic, y_train_classic)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Training time: {round(elapsed)} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cffe5-06e6-4984-bf1d-0b3fc4cb3fb8",
   "metadata": {},
   "source": [
    "### 3.1.3 Treinamento com Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9daaf97-e838-48b3-a43f-01a8209a080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X_train, y_train):\n",
    "    from sklearn.svm import SVC\n",
    "    import time\n",
    "    \n",
    "    model = SVC(kernel='linear', probability=True)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train_classic, y_train_classic)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Training time: {round(elapsed)} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb9e48-a1e4-41db-a399-06c588b2350e",
   "metadata": {},
   "source": [
    "## 3.2 Treinamento dos modelos quânticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff5162-bb58-4c78-8090-f730dd3c5ff2",
   "metadata": {},
   "source": [
    "### 3.2.1 Treinamento com Variational Quantum Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4d9f1-8242-4839-ab25-5efd6c7d5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vqc(X_train, y_train, num_features):\n",
    "    from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "    from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
    "    from qiskit_machine_learning.optimizers import COBYLA\n",
    "    from qiskit.primitives import StatevectorSampler as Sampler\n",
    "    import time\n",
    "    \n",
    "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
    "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
    "    optimizer = COBYLA(maxiter=100)\n",
    "    sampler = Sampler()\n",
    "    \n",
    "    model = VQC(\n",
    "        sampler=sampler,\n",
    "        feature_map=feature_map,\n",
    "        ansatz=ansatz,\n",
    "        optimizer=optimizer,\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"VQC - Training time: {round(elapsed)} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7193f4c-d5a1-4a4f-b220-ad04b0de4640",
   "metadata": {},
   "source": [
    "# 4. Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0868a-f48f-45da-8a31-ecdbd77e67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred_lcr = lcr.predict(X_test_classic)\n",
    "y_pred_rfc = rfc.predict(X_test_classic)\n",
    "y_pred_svm = svm.predict(X_test_classic)\n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1 Score:', f1, \"\\n\")\n",
    "\n",
    "print(\"Regressão Logística\")\n",
    "evaluate_model(y_test_classic, y_pred_lcr)\n",
    "\n",
    "print(\"Floresta Aleatória\")\n",
    "evaluate_model(y_test_classic, y_pred_rfc)\n",
    "\n",
    "print(\"Support Vector Classifier \")\n",
    "evaluate_model(y_test_classic, y_pred_svm)\n",
    "\n",
    "print(\"Variational Quantum Classifier\")\n",
    "evaluate_model(y_test_quantum, y_pred_vqc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
