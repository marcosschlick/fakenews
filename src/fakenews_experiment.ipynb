{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5346f561-821b-4484-8949-ef5afd65b317",
   "metadata": {},
   "source": [
    "# 0. Configurações para usar o Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370172da-568e-4e82-8233-a25d40b98cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install qiskit-machine-learning pylatexenc nltk kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c76d9-7707-494c-be3a-34f7772b6e4d",
   "metadata": {},
   "source": [
    "# 1. Carregar o dataset e explorar a estrutura do dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9f540-4d12-45bc-9bd0-955f25d18633",
   "metadata": {},
   "source": [
    "## 1.1 Caso esteja usando Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aabe3be-9e9c-4f36-aeb5-5c92d38f8dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# download do dataset\n",
    "path = kagglehub.dataset_download(\"saurabhshahane/fake-news-classification\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# carregar o dataset\n",
    "dataset_path = os.path.join(path, \"WELFake_Dataset.csv\") \n",
    "\n",
    "# carregar o dataframe, embaralhar os dados, resetar os index e remover coluna \"Unnamed\" inútil\n",
    "dataframe = (\n",
    "    pd.read_csv(dataset_path)\n",
    "    .sample(frac=1)\n",
    "    .reset_index(drop=True)\n",
    "    .drop(\"Unnamed: 0\", axis=\"columns\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82def228-0ccf-450d-b6ad-1d601de47737",
   "metadata": {},
   "source": [
    "## 1.2 Caso esteja usando sua máquina local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5bc9b3-157a-4b72-8ba2-439b32996dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# carregar o dataframe, embaralhar os dados, resetar os index e remover coluna \"Unnamed\" inútil\n",
    "dataframe = (\n",
    "    pd.read_csv('../dataset/WELFake_Dataset.csv')\n",
    "    .sample(frac=1)\n",
    "    .reset_index(drop=True)\n",
    "    .drop(\"Unnamed: 0\", axis=\"columns\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1914f3-f27e-4cfa-809c-8cc53d0a6e2f",
   "metadata": {},
   "source": [
    "## 1.3 Vizualizar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da36513b-12e5-4c30-8558-8f0bdddde921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra as primeiras 5 linhas do df\n",
    "print(\"Primeiras 5 linhas do dataframe:\")\n",
    "print(dataframe.head())\n",
    "\n",
    "# mostra a quantidade de linhas e colunas\n",
    "print(f\"\\nQuantidade de linhas x colunas: {dataframe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f65a7d-bc22-41cc-888a-61e8cacc6055",
   "metadata": {},
   "source": [
    "# 2. Pré processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b2203-3318-4d04-a8e3-5d32e8d71fbc",
   "metadata": {},
   "source": [
    "## 2.1 Remover rows com campos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccc9ed3-cc94-4e46-b3f4-8ad4f985ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra informações do dataframe\n",
    "print(\"Informações sobre os tipos de dados e quantidades de nulos:\")\n",
    "dataframe.info()\n",
    "\n",
    "# apaga as linhas que tem \"title\" ou \"text\" nulos, \n",
    "dataframe.dropna(subset=[\"title\", \"text\"], inplace=True) # implace ao invés de retornar um novo dataframe ele altera o original direto\n",
    "\n",
    "print(\"\\nApós apagar os nulos:\")\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d589b83d-3842-4446-ba34-405071dff209",
   "metadata": {},
   "source": [
    "## 2.2 Verificar a distribuição entre notícias reais e falsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ddca6-0ab9-4825-abd0-3757f6c50882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nContagem de labels após remover nulos  (1 = real, 0 = fake):\")\n",
    "print(dataframe['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce87f7-02bc-4144-b268-e5153ce57c4a",
   "metadata": {},
   "source": [
    "## 2.3 Criar dataframes com tamanho reduzido para clássicos e quânticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2453cd7-cc47-4b83-8d5d-4eb86e6e9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar dataframes para os modelos clássicos\n",
    "df_classic_0k = dataframe[:100].copy()\n",
    "df_classic_1k = dataframe[:1000].copy()\n",
    "df_classic_10k = dataframe[:10000].copy()\n",
    "df_classic_30k = dataframe[:30000].copy()\n",
    "df_classic_50k = dataframe[:50000].copy()\n",
    "df_classic = dataframe.copy()\n",
    "\n",
    "# criar dataframes para os modelos quânticos\n",
    "df_quantum_0k = df_classic_0k.copy()\n",
    "df_quantum_1k = df_classic_1k.copy()\n",
    "df_quantum_10k = df_classic_10k.copy()\n",
    "df_quantum_30k = df_classic_30k.copy()\n",
    "df_quantum_50k = df_classic_50k.copy()\n",
    "df_quantum = df_classic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53593c2f-7438-471a-9358-4123fcb4c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar distribuição entre as labels\n",
    "print(f\"Classic 0k - Total samples: {len(df_classic_0k)}\")\n",
    "print(df_classic_0k['label'].value_counts())\n",
    "print()\n",
    "\n",
    "print(f\"Classic 1k - Total samples: {len(df_classic_1k)}\")\n",
    "print(df_classic_1k['label'].value_counts())\n",
    "print()\n",
    "\n",
    "print(f\"Classic 10k - Total samples: {len(df_classic_10k)}\")\n",
    "print(df_classic_10k['label'].value_counts())\n",
    "print()\n",
    "\n",
    "print(f\"Classic 30k - Total samples: {len(df_classic_30k)}\")\n",
    "print(df_classic_30k['label'].value_counts())\n",
    "print()\n",
    "\n",
    "print(f\"Classic 50k - Total samples: {len(df_classic_50k)}\")\n",
    "print(df_classic_50k['label'].value_counts())\n",
    "print()\n",
    "\n",
    "print(f\"Classic Full - Total samples: {len(df_classic)}\")\n",
    "print(df_classic['label'].value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab7c6d-c18e-4838-a455-d47e5a5c2f5f",
   "metadata": {},
   "source": [
    "## 2.4 Aplicar pré-processamento para todos os dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2cddfd-8125-4bb5-b410-9443a29be50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download(\"punkt\") # remove as pontuações\n",
    "nltk.download('punkt_tab') \n",
    "nltk.download(\"stopwords\") # remove as stop words \n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # letras minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove menções e hashtags (comum em dados de redes sociais)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "\n",
    "    # remove a pontuação e os digitos\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
    "\n",
    "    # tokenizar o texto\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # remover as stop words (palavras irrelevantes como artigos e pronomes)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Aplicar Stemming (remover o sufixo das palavaras exemplo \"mudando\" \"mudaria\" para \"mud\") \n",
    "    # ou lemmatizing (mais sofisticado reduz a palavra para a forma base \"mudaria\" ou \"mudado\" viraria mudar)\n",
    "    \n",
    "    # aplicar lemmatizer nas palavras\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "   \n",
    "    # junta as palavras de volta numa string\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb42eac-a06c-498f-9a9f-548b268bdff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar pré-processamento nos dataframes clássicos\n",
    "df_classic_0k['text_clean'] = df_classic_0k['text'].apply(preprocess_text)\n",
    "df_classic_1k['text_clean'] = df_classic_1k['text'].apply(preprocess_text)\n",
    "df_classic_10k['text_clean'] = df_classic_10k['text'].apply(preprocess_text)\n",
    "df_classic_30k['text_clean'] = df_classic_30k['text'].apply(preprocess_text)\n",
    "df_classic_50k['text_clean'] = df_classic_50k['text'].apply(preprocess_text)\n",
    "df_classic['text_clean'] = df_classic['text'].apply(preprocess_text)\n",
    "\n",
    "# Aplicar pré-processamento nos dataframes quânticos\n",
    "df_quantum_0k['text_clean'] = df_quantum_0k['text'].apply(preprocess_text)\n",
    "df_quantum_1k['text_clean'] = df_quantum_1k['text'].apply(preprocess_text)\n",
    "df_quantum_10k['text_clean'] = df_quantum_10k['text'].apply(preprocess_text)\n",
    "df_quantum_30k['text_clean'] = df_quantum_30k['text'].apply(preprocess_text)\n",
    "df_quantum_50k['text_clean'] = df_quantum_50k['text'].apply(preprocess_text)\n",
    "df_quantum['text_clean'] = df_quantum['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb84181-4d00-4ef4-87f0-d80f92ac4499",
   "metadata": {},
   "source": [
    "# 3. Treinamento dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229c9f3-0061-40e5-8554-17ee55fdc12d",
   "metadata": {},
   "source": [
    "## 3.1 Preparação dos dados para o treinamento dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc5cec1-a4d8-43a6-8b0a-5b3250fb89f4",
   "metadata": {},
   "source": [
    "### 3.1.1 Prepara dados para modelos clássicos usando TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945fe033-6dee-4691-aa01-1613f12c5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def prepare_classical_data(df):\n",
    "    y = df['label'].values\n",
    "    \n",
    "    # Cria e aplica TF-IDF\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X = vectorizer.fit_transform(df['text_clean'])\n",
    "    \n",
    "    # Split treino/teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602798a-31b8-458c-b75c-d933352088a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para modelos clássicos\n",
    "X_train_classic_0k, X_test_classic_0k, y_train_classic_0k, y_test_classic_0k, vectorizer_classic_0k = prepare_classical_data(df_classic_0k)\n",
    "\n",
    "X_train_classic_1k, X_test_classic_1k, y_train_classic_1k, y_test_classic_1k, vectorizer_classic_1k = prepare_classical_data(df_classic_1k)\n",
    "\n",
    "X_train_classic_10k, X_test_classic_10k, y_train_classic_10k, y_test_classic_10k, vectorizer_classic_10k = prepare_classical_data(df_classic_10k)\n",
    "\n",
    "X_train_classic_30k, X_test_classic_30k, y_train_classic_30k, y_test_classic_30k, vectorizer_classic_30k = prepare_classical_data(df_classic_30k)\n",
    "\n",
    "X_train_classic_50k, X_test_classic_50k, y_train_classic_50k, y_test_classic_50k, vectorizer_classic_50k = prepare_classical_data(df_classic_50k)\n",
    "\n",
    "X_train_classic, X_test_classic, y_train_classic, y_test_classic, vectorizer_classic = prepare_classical_data(df_classic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadce33e-7387-4306-828e-6bdcd099462b",
   "metadata": {},
   "source": [
    "### 3.1.2 Prepara dados para modelos quânticos usando TF-IDF + Lasso Selector + Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320bc807-01f7-46d3-adf0-0e8c72fcb6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_quantum_data(df, max_features=12, n_components=8):\n",
    "    y = df['label'].values\n",
    "    \n",
    "    # Cria e aplica TF-IDF\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X = vectorizer.fit_transform(df['text_clean'])\n",
    "    \n",
    "    # Seleção de features com Lasso\n",
    "    lasso_selector = SelectFromModel(\n",
    "        LogisticRegression(random_state=42, penalty='l1', solver='liblinear'),\n",
    "        max_features=max_features\n",
    "    )\n",
    "    X = lasso_selector.fit_transform(X, y)\n",
    "    \n",
    "    # Escalonamento dos dados\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    n_components_or_n_features = min(n_components, X_scaled.shape[1])\n",
    "\n",
    "    # Aplica o PCA\n",
    "    pca = PCA(n_components=n_components_or_n_features)\n",
    "    X_pca = pca.fit_transform(X_scaled.toarray()) \n",
    "    \n",
    "    print(f\"PCA: {X_scaled.shape[1]} features → {X_pca.shape[1]} componentes\")\n",
    "    print(f\"Variância explicada: {sum(pca.explained_variance_ratio_):.2%}\")\n",
    "    \n",
    "    # Split treino/teste \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_pca, y, test_size=0.2, random_state=42  \n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, vectorizer, lasso_selector, scaler, pca  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9935665-4964-4791-865c-dba2767a41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para modelos quânticos\n",
    "X_train_quantum_0k, X_test_quantum_0k, y_train_quantum_0k, y_test_quantum_0k, vectorizer_quantum_0k, lasso_selector_quantum_0k, scaler_quantum_0k, pca_quantum_0k = prepare_quantum_data(df_quantum_0k)\n",
    "\n",
    "X_train_quantum_1k, X_test_quantum_1k, y_train_quantum_1k, y_test_quantum_1k, vectorizer_quantum_1k, lasso_selector_quantum_1k, scaler_quantum_1k, pca_quantum_1k = prepare_quantum_data(df_quantum_1k)\n",
    "\n",
    "X_train_quantum_10k, X_test_quantum_10k, y_train_quantum_10k, y_test_quantum_10k, vectorizer_quantum_10k, lasso_selector_quantum_10k, scaler_quantum_10k, pca_quantum_10k = prepare_quantum_data(df_quantum_10k)\n",
    "\n",
    "X_train_quantum_30k, X_test_quantum_30k, y_train_quantum_30k, y_test_quantum_30k, vectorizer_quantum_30k, lasso_selector_quantum_30k, scaler_quantum_30k, pca_quantum_30k = prepare_quantum_data(df_quantum_30k)\n",
    "\n",
    "X_train_quantum_50k, X_test_quantum_50k, y_train_quantum_50k, y_test_quantum_50k, vectorizer_quantum_50k, lasso_selector_quantum_50k, scaler_quantum_50k, pca_quantum_50k = prepare_quantum_data(df_quantum_50k)\n",
    "\n",
    "X_train_quantum, X_test_quantum, y_train_quantum, y_test_quantum, vectorizer_quantum, lasso_selector_quantum, scaler_quantum, pca_quantum = prepare_quantum_data(df_quantum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d22dca-9567-4174-883f-99e6ba5aa38c",
   "metadata": {},
   "source": [
    "## 3.2 Treinamento dos modelos clássicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be148190-e393-4063-b477-cd3b9c84b80b",
   "metadata": {},
   "source": [
    "### 3.2.1 Treinamento com Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fe379-1623-4e1b-92b7-b33d7a82c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import time\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Training time: {round(elapsed)} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f6c7a-7471-42e1-8fc2-69b767420810",
   "metadata": {},
   "source": [
    "### 3.2.2 Treinamento com Floresta Aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0db03-016d-4b87-959a-457ec1df97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import time\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Training time: {round(elapsed)} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cffe5-06e6-4984-bf1d-0b3fc4cb3fb8",
   "metadata": {},
   "source": [
    "### 3.2.3 Treinamento com Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9daaf97-e838-48b3-a43f-01a8209a080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X_train, y_train):\n",
    "    from sklearn.svm import SVC\n",
    "    import time\n",
    "    \n",
    "    model = SVC(kernel='linear', probability=True)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Training time: {round(elapsed)} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf5e42e-6011-4c5f-949b-a0f925551d19",
   "metadata": {},
   "source": [
    "### 3.2.4 Treinamento com Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ea36a4-97fd-452f-9db1-1267ef59af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(X_train, y_train):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    import time\n",
    "\n",
    "    model = MultinomialNB()\n",
    "\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Training time: {round(elapsed)} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d8ce2-d806-4b4a-be46-a42f2f564110",
   "metadata": {},
   "source": [
    "### 3.2.5 Treinamento com K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5a0db-1bc0-4840-815e-29ee706c9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(X_train, y_train, n_neighbors=5):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    import time\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Training time: {round(elapsed)} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb9e48-a1e4-41db-a399-06c588b2350e",
   "metadata": {},
   "source": [
    "## 3.3 Treinamento dos modelos quânticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff5162-bb58-4c78-8090-f730dd3c5ff2",
   "metadata": {},
   "source": [
    "### 3.3.1 Treinamento com Variational Quantum Classifier (VQC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4d9f1-8242-4839-ab25-5efd6c7d5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vqc(X_train, y_train, num_features):\n",
    "    from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "    from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
    "    from qiskit_machine_learning.optimizers import COBYLA\n",
    "    import time\n",
    "    \n",
    "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
    "\n",
    "    # define o ansatz RealAmplitudes\n",
    "    ansatz = RealAmplitudes(num_qubits=num_features, reps=2)\n",
    "\n",
    "    # define o otimizador COBYLA \n",
    "    optimizer = COBYLA(maxiter=50)\n",
    "\n",
    "    # inicializa o classificador VQC\n",
    "    model = VQC(\n",
    "        feature_map=feature_map,\n",
    "        ansatz=ansatz,\n",
    "        optimizer=optimizer,\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Training time: {round(elapsed)} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a46bfdc4-2eb3-43fd-9e34-cc5d054921d4",
   "metadata": {},
   "source": [
    "### 3.3.2 Treinamento com Quantum Neural Network (QNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413c44a-64f7-4f06-9f1f-d81f54abcc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit.primitives import Estimator\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "import time\n",
    "\n",
    "def train_qnn(X_train, y_train, num_features):   \n",
    "    # Criar circuito quântico \n",
    "    qc = QuantumCircuit(num_features)\n",
    "    \n",
    "    # Criar parâmetros para inputs e weights\n",
    "    input_params = [Parameter(f'input_{i}') for i in range(num_features)]\n",
    "    weight_params = [Parameter(f'weight_{i}') for i in range(num_features)]\n",
    "    \n",
    "    # Adicionar operações ao circuito \n",
    "    for i in range(num_features):\n",
    "        qc.ry(input_params[i], i)  # Rotações Y com parâmetros de input\n",
    "    \n",
    "    # Adicionar camada parametrizada (weights)\n",
    "    for i in range(num_features):\n",
    "        qc.rz(weight_params[i], i)  # Rotações Z com parâmetros de weight\n",
    "    \n",
    "    # Adicionar algum entrelaçamento\n",
    "    for i in range(num_features - 1):\n",
    "        qc.cx(i, i + 1)\n",
    "    \n",
    "    # Definir observável (Z no primeiro qubit)\n",
    "    observable = SparsePauliOp(\"Z\" + \"I\" * (num_features - 1))\n",
    "    \n",
    "    # Criar a QNN usando EstimatorQNN \n",
    "    estimator = Estimator()\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        observables=observable,\n",
    "        input_params=input_params,\n",
    "        weight_params=weight_params,\n",
    "        estimator=estimator\n",
    "    )\n",
    "    \n",
    "    # Criar classificador com a QNN\n",
    "    model = NeuralNetworkClassifier(\n",
    "        neural_network=qnn,\n",
    "        optimizer=COBYLA(maxiter=50),\n",
    "        initial_point=[0.0] * len(weight_params)  # Ponto inicial para os weights\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Training time: {round(elapsed)} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7193f4c-d5a1-4a4f-b220-ad04b0de4640",
   "metadata": {},
   "source": [
    "# 4. Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635701c-4cf2-48bd-baf8-fa7bbed4514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred, model_name, dataset_size):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f'Matriz de Confusão - {model_name} ({dataset_size})')\n",
    "    plt.show()\n",
    "    \n",
    "    # print dos valores\n",
    "    print(f\"Verdadeiros Negativos (Fake): {cm[0][0]}\")\n",
    "    print(f\"Falsos Positivos: {cm[0][1]}\")\n",
    "    print(f\"Falsos Negativos: {cm[1][0]}\")\n",
    "    print(f\"Verdadeiros Positivos (Real): {cm[1][1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838461a-2682-4867-97c6-570f0c9d6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "\n",
    "def evaluate_model(y_test, y_pred, model_name=\"Modelo\", dataset_size=\"Dataset\"):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1 Score:', f1, \"\\n\")\n",
    "    plot_confusion_matrix(y_test, y_pred, model_name, dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55234a2-86f3-4623-8c3a-c01f05539d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_and_evaluate_model(train_function, X_train, X_test, y_train, y_test, model_name, dataset_size):\n",
    "    # treina o modelo\n",
    "    model = train_function(X_train, y_train)\n",
    "    \n",
    "    # mede o tempo de inferência\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Inference time: {elapsed:.4f} seconds\")\n",
    "    \n",
    "    # avalia o modelo\n",
    "    evaluate_model(y_test, y_pred, model_name, dataset_size)\n",
    "    \n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32751b3d-4bda-4d65-84de-e1fc41ed4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_and_evaluate_vqc(X_train, X_test, y_train, y_test, model_name, dataset_size, num_features):\n",
    "    # treina o modelo\n",
    "    model = train_vqc(X_train, y_train, num_features)\n",
    "    \n",
    "    # mede o tempo de inferência\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Inference time: {elapsed:.4f} seconds\")\n",
    "    \n",
    "    # avalia o modelo\n",
    "    evaluate_model(y_test, y_pred, model_name, dataset_size)\n",
    "    \n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a69908e-051c-4448-aef1-b606639fc63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_and_evaluate_knn(X_train, X_test, y_train, y_test, model_name, dataset_size, n_neighbors=5):\n",
    "    # treina o modelo\n",
    "    model = train_knn(X_train, y_train, n_neighbors)\n",
    "    \n",
    "    # mede o tempo de inferência\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Inference time: {elapsed:.4f} seconds\")\n",
    "    \n",
    "    # avalia o modelo\n",
    "    evaluate_model(y_test, y_pred, model_name, dataset_size)\n",
    "    \n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb689b5-536b-4046-b65d-28ea5aa47dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_and_evaluate_qnn(X_train, X_test, y_train, y_test, model_name, dataset_size, num_features):\n",
    "    # treina o modelo\n",
    "    model = train_qnn(X_train, y_train, num_features)\n",
    "    \n",
    "    # mede o tempo de inferência\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Inference time: {elapsed:.4f} seconds\")\n",
    "    \n",
    "    # avalia o modelo\n",
    "    evaluate_model(y_test, y_pred, model_name, dataset_size)\n",
    "    \n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f324e82-8001-46fd-bbde-089afbac69f0",
   "metadata": {},
   "source": [
    "## 4.1 Avaliação da Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d613e15-3add-4474-b02f-cdc4a99f740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação da Regressão Logística\n",
    "print(\"=\" * 50)\n",
    "print(\"REGRESSÃO LOGÍSTICA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Classic 0k\n",
    "print(\"\\n--- Classic 0k ---\")\n",
    "lcr_0k, y_pred_lcr_0k = train_and_evaluate_model(\n",
    "    train_logistic_regression, \n",
    "    X_train_classic_0k, X_test_classic_0k, \n",
    "    y_train_classic_0k, y_test_classic_0k,\n",
    "    \"Regressão Logística\", \"0k\"\n",
    ")\n",
    "\n",
    "# Classic 1k\n",
    "print(\"\\n--- Classic 1k ---\")\n",
    "lcr_1k, y_pred_lcr_1k = train_and_evaluate_model(\n",
    "    train_logistic_regression, \n",
    "    X_train_classic_1k, X_test_classic_1k, \n",
    "    y_train_classic_1k, y_test_classic_1k,\n",
    "    \"Regressão Logística\", \"1k\"\n",
    ")\n",
    "\n",
    "# Classic 10k\n",
    "print(\"\\n--- Classic 10k ---\")\n",
    "lcr_10k, y_pred_lcr_10k = train_and_evaluate_model(\n",
    "    train_logistic_regression, \n",
    "    X_train_classic_10k, X_test_classic_10k, \n",
    "    y_train_classic_10k, y_test_classic_10k,\n",
    "    \"Regressão Logística\", \"10k\"\n",
    ")\n",
    "\n",
    "# Classic 30k\n",
    "print(\"\\n--- Classic 30k ---\")\n",
    "lcr_30k, y_pred_lcr_30k = train_and_evaluate_model(\n",
    "    train_logistic_regression, \n",
    "    X_train_classic_30k, X_test_classic_30k, \n",
    "    y_train_classic_30k, y_test_classic_30k,\n",
    "    \"Regressão Logística\", \"30k\"\n",
    ")\n",
    "\n",
    "# Classic 50k\n",
    "print(\"\\n--- Classic 50k ---\")\n",
    "lcr_50k, y_pred_lcr_50k = train_and_evaluate_model(\n",
    "    train_logistic_regression, \n",
    "    X_train_classic_50k, X_test_classic_50k, \n",
    "    y_train_classic_50k, y_test_classic_50k,\n",
    "    \"Regressão Logística\", \"50k\"\n",
    ")\n",
    "\n",
    "# Classic Full\n",
    "print(\"\\n--- Classic Full ---\")\n",
    "lcr_full, y_pred_lcr_full = train_and_evaluate_model(\n",
    "    train_logistic_regression, \n",
    "    X_train_classic, X_test_classic, \n",
    "    y_train_classic, y_test_classic,\n",
    "    \"Regressão Logística\", \"Full\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf3f83-c9ad-40cd-acd5-d5be11914c40",
   "metadata": {},
   "source": [
    "## 4.2 Avaliação da Floresta Aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16390ad-c33c-4e2f-aeb9-6762a13f6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação da Floresta Aleatória\n",
    "print(\"=\" * 50)\n",
    "print(\"FLORESTA ALEATÓRIA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Classic 0k\n",
    "print(\"\\n--- Classic 0k ---\")\n",
    "rfc_0k, y_pred_rfc_0k = train_and_evaluate_model(\n",
    "    train_random_forest, \n",
    "    X_train_classic_0k, X_test_classic_0k, \n",
    "    y_train_classic_0k, y_test_classic_0k,\n",
    "    \"Floresta Aleatória\", \"0k\"\n",
    ")\n",
    "\n",
    "# Classic 1k\n",
    "print(\"\\n--- Classic 1k ---\")\n",
    "rfc_1k, y_pred_rfc_1k = train_and_evaluate_model(\n",
    "    train_random_forest, \n",
    "    X_train_classic_1k, X_test_classic_1k, \n",
    "    y_train_classic_1k, y_test_classic_1k,\n",
    "    \"Floresta Aleatória\", \"1k\"\n",
    ")\n",
    "\n",
    "# Classic 10k\n",
    "print(\"\\n--- Classic 10k ---\")\n",
    "rfc_10k, y_pred_rfc_10k = train_and_evaluate_model(\n",
    "    train_random_forest, \n",
    "    X_train_classic_10k, X_test_classic_10k, \n",
    "    y_train_classic_10k, y_test_classic_10k,\n",
    "    \"Floresta Aleatória\", \"10k\"\n",
    ")\n",
    "\n",
    "# Classic 30k\n",
    "print(\"\\n--- Classic 30k ---\")\n",
    "rfc_30k, y_pred_rfc_30k = train_and_evaluate_model(\n",
    "    train_random_forest, \n",
    "    X_train_classic_30k, X_test_classic_30k, \n",
    "    y_train_classic_30k, y_test_classic_30k,\n",
    "    \"Floresta Aleatória\", \"30k\"\n",
    ")\n",
    "\n",
    "# Classic 50k\n",
    "print(\"\\n--- Classic 50k ---\")\n",
    "rfc_50k, y_pred_rfc_50k = train_and_evaluate_model(\n",
    "    train_random_forest, \n",
    "    X_train_classic_50k, X_test_classic_50k, \n",
    "    y_train_classic_50k, y_test_classic_50k,\n",
    "    \"Floresta Aleatória\", \"50k\"\n",
    ")\n",
    "\n",
    "# Classic Full\n",
    "print(\"\\n--- Classic Full ---\")\n",
    "rfc_full, y_pred_rfc_full = train_and_evaluate_model(\n",
    "    train_random_forest, \n",
    "    X_train_classic, X_test_classic, \n",
    "    y_train_classic, y_test_classic,\n",
    "    \"Floresta Aleatória\", \"Full\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b38f2-0e47-4ea8-ab25-f780edb2b19c",
   "metadata": {},
   "source": [
    "## 4.3 Avaliação do Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2cdfd2-ffb9-44ff-9878-ae31078ddc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do Support Vector Classifier\n",
    "print(\"=\" * 50)\n",
    "print(\"SUPPORT VECTOR CLASSIFIER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Classic 0k\n",
    "print(\"\\n--- Classic 0k ---\")\n",
    "svm_0k, y_pred_svm_0k = train_and_evaluate_model(\n",
    "    train_svm, \n",
    "    X_train_classic_0k, X_test_classic_0k, \n",
    "    y_train_classic_0k, y_test_classic_0k,\n",
    "    \"Support Vector Classifier\", \"0k\"\n",
    ")\n",
    "\n",
    "# Classic 1k\n",
    "print(\"\\n--- Classic 1k ---\")\n",
    "svm_1k, y_pred_svm_1k = train_and_evaluate_model(\n",
    "    train_svm, \n",
    "    X_train_classic_1k, X_test_classic_1k, \n",
    "    y_train_classic_1k, y_test_classic_1k,\n",
    "    \"Support Vector Classifier\", \"1k\"\n",
    ")\n",
    "\n",
    "# Classic 10k\n",
    "print(\"\\n--- Classic 10k ---\")\n",
    "svm_10k, y_pred_svm_10k = train_and_evaluate_model(\n",
    "    train_svm, \n",
    "    X_train_classic_10k, X_test_classic_10k, \n",
    "    y_train_classic_10k, y_test_classic_10k,\n",
    "    \"Support Vector Classifier\", \"10k\"\n",
    ")\n",
    "\n",
    "# Classic 30k\n",
    "print(\"\\n--- Classic 30k ---\")\n",
    "svm_30k, y_pred_svm_30k = train_and_evaluate_model(\n",
    "    train_svm, \n",
    "    X_train_classic_30k, X_test_classic_30k, \n",
    "    y_train_classic_30k, y_test_classic_30k,\n",
    "    \"Support Vector Classifier\", \"30k\"\n",
    ")\n",
    "\n",
    "# Classic 50k\n",
    "print(\"\\n--- Classic 50k ---\")\n",
    "svm_50k, y_pred_svm_50k = train_and_evaluate_model(\n",
    "    train_svm, \n",
    "    X_train_classic_50k, X_test_classic_50k, \n",
    "    y_train_classic_50k, y_test_classic_50k,\n",
    "    \"Support Vector Classifier\", \"50k\"\n",
    ")\n",
    "\n",
    "# Classic Full\n",
    "print(\"\\n--- Classic Full ---\")\n",
    "svm_full, y_pred_svm_full = train_and_evaluate_model(\n",
    "    train_svm, \n",
    "    X_train_classic, X_test_classic, \n",
    "    y_train_classic, y_test_classic,\n",
    "    \"Support Vector Classifier\", \"Full\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fe778-6233-4650-9b53-5c3945691ca5",
   "metadata": {},
   "source": [
    "## 4.4 Avaliação do Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1febf0d4-c1b9-4e09-9ec3-43d628009658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do Naive Bayes\n",
    "print(\"=\" * 50)\n",
    "print(\"NAIVE BAYES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Classic 0k\n",
    "print(\"\\n--- Classic 0k ---\")\n",
    "nb_0k, y_pred_nb_0k = train_and_evaluate_model(\n",
    "    train_naive_bayes, \n",
    "    X_train_classic_0k, X_test_classic_0k, \n",
    "    y_train_classic_0k, y_test_classic_0k,\n",
    "    \"Naive Bayes\", \"0k\"\n",
    ")\n",
    "\n",
    "# Classic 1k\n",
    "print(\"\\n--- Classic 1k ---\")\n",
    "nb_1k, y_pred_nb_1k = train_and_evaluate_model(\n",
    "    train_naive_bayes, \n",
    "    X_train_classic_1k, X_test_classic_1k, \n",
    "    y_train_classic_1k, y_test_classic_1k,\n",
    "    \"Naive Bayes\", \"1k\"\n",
    ")\n",
    "\n",
    "# Classic 10k\n",
    "print(\"\\n--- Classic 10k ---\")\n",
    "nb_10k, y_pred_nb_10k = train_and_evaluate_model(\n",
    "    train_naive_bayes, \n",
    "    X_train_classic_10k, X_test_classic_10k, \n",
    "    y_train_classic_10k, y_test_classic_10k,\n",
    "    \"Naive Bayes\", \"10k\"\n",
    ")\n",
    "\n",
    "# Classic 30k\n",
    "print(\"\\n--- Classic 30k ---\")\n",
    "nb_30k, y_pred_nb_30k = train_and_evaluate_model(\n",
    "    train_naive_bayes, \n",
    "    X_train_classic_30k, X_test_classic_30k, \n",
    "    y_train_classic_30k, y_test_classic_30k,\n",
    "    \"Naive Bayes\", \"30k\"\n",
    ")\n",
    "\n",
    "# Classic 50k\n",
    "print(\"\\n--- Classic 50k ---\")\n",
    "nb_50k, y_pred_nb_50k = train_and_evaluate_model(\n",
    "    train_naive_bayes, \n",
    "    X_train_classic_50k, X_test_classic_50k, \n",
    "    y_train_classic_50k, y_test_classic_50k,\n",
    "    \"Naive Bayes\", \"50k\"\n",
    ")\n",
    "\n",
    "# Classic Full\n",
    "print(\"\\n--- Classic Full ---\")\n",
    "nb_full, y_pred_nb_full = train_and_evaluate_model(\n",
    "    train_naive_bayes, \n",
    "    X_train_classic, X_test_classic, \n",
    "    y_train_classic, y_test_classic,\n",
    "    \"Naive Bayes\", \"Full\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a9ab7-e18d-4868-bdde-f2121cdb8843",
   "metadata": {},
   "source": [
    "## 4.5 Avaliação do K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16853918-f57c-4a52-9b38-e91c618e6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do K-Nearest Neighbors\n",
    "print(\"=\" * 50)\n",
    "print(\"K-NEAREST NEIGHBORS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Classic 0k\n",
    "print(\"\\n--- Classic 0k ---\")\n",
    "knn_0k, y_pred_knn_0k = train_and_evaluate_knn(\n",
    "    X_train_classic_0k, X_test_classic_0k, \n",
    "    y_train_classic_0k, y_test_classic_0k,\n",
    "    \"K-Nearest Neighbors\", \"0k\", n_neighbors=5\n",
    ")\n",
    "\n",
    "# Classic 1k\n",
    "print(\"\\n--- Classic 1k ---\")\n",
    "knn_1k, y_pred_knn_1k = train_and_evaluate_knn(\n",
    "    X_train_classic_1k, X_test_classic_1k, \n",
    "    y_train_classic_1k, y_test_classic_1k,\n",
    "    \"K-Nearest Neighbors\", \"1k\", n_neighbors=5\n",
    ")\n",
    "\n",
    "# Classic 10k\n",
    "print(\"\\n--- Classic 10k ---\")\n",
    "knn_10k, y_pred_knn_10k = train_and_evaluate_knn(\n",
    "    X_train_classic_10k, X_test_classic_10k, \n",
    "    y_train_classic_10k, y_test_classic_10k,\n",
    "    \"K-Nearest Neighbors\", \"10k\", n_neighbors=5\n",
    ")\n",
    "\n",
    "# Classic 30k\n",
    "print(\"\\n--- Classic 30k ---\")\n",
    "knn_30k, y_pred_knn_30k = train_and_evaluate_knn(\n",
    "    X_train_classic_30k, X_test_classic_30k, \n",
    "    y_train_classic_30k, y_test_classic_30k,\n",
    "    \"K-Nearest Neighbors\", \"30k\", n_neighbors=5\n",
    ")\n",
    "\n",
    "# Classic 50k\n",
    "print(\"\\n--- Classic 50k ---\")\n",
    "knn_50k, y_pred_knn_50k = train_and_evaluate_knn(\n",
    "    X_train_classic_50k, X_test_classic_50k, \n",
    "    y_train_classic_50k, y_test_classic_50k,\n",
    "    \"K-Nearest Neighbors\", \"50k\", n_neighbors=5\n",
    ")\n",
    "\n",
    "# Classic Full\n",
    "print(\"\\n--- Classic Full ---\")\n",
    "knn_full, y_pred_knn_full = train_and_evaluate_knn(\n",
    "    X_train_classic, X_test_classic, \n",
    "    y_train_classic, y_test_classic,\n",
    "    \"K-Nearest Neighbors\", \"Full\", n_neighbors=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71334af8-f354-4959-934c-e89e06140477",
   "metadata": {},
   "source": [
    "## 4.6 Avaliação do Variational Quantum Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b7041-05a1-45b4-8ade-38349fcf4f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do Variational Quantum Classifier\n",
    "print(\"=\" * 50)\n",
    "print(\"VARIATIONAL QUANTUM CLASSIFIER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Quantum 0k\n",
    "print(\"\\n--- Quantum 0k ---\")\n",
    "vqc_0k, y_pred_vqc_0k = train_and_evaluate_vqc(\n",
    "    X_train_quantum_0k, X_test_quantum_0k, \n",
    "    y_train_quantum_0k, y_test_quantum_0k,\n",
    "    \"Variational Quantum Classifier\", \"0k\", X_train_quantum_0k.shape[1]\n",
    ")\n",
    "\n",
    "# Quantum 1k\n",
    "print(\"\\n--- Quantum 1k ---\")\n",
    "vqc_1k, y_pred_vqc_1k = train_and_evaluate_vqc(\n",
    "    X_train_quantum_1k, X_test_quantum_1k, \n",
    "    y_train_quantum_1k, y_test_quantum_1k,\n",
    "    \"Variational Quantum Classifier\", \"1k\", X_train_quantum_1k.shape[1]\n",
    ")\n",
    "\n",
    "# Quantum 10k\n",
    "print(\"\\n--- Quantum 10k ---\")\n",
    "vqc_10k, y_pred_vqc_10k = train_and_evaluate_vqc(\n",
    "    X_train_quantum_10k, X_test_quantum_10k, \n",
    "    y_train_quantum_10k, y_test_quantum_10k,\n",
    "    \"Variational Quantum Classifier\", \"10k\", X_train_quantum_10k.shape[1]\n",
    ")\n",
    "\n",
    "# Quantum 30k\n",
    "print(\"\\n--- Quantum 30k ---\")\n",
    "vqc_30k, y_pred_vqc_30k = train_and_evaluate_vqc(\n",
    "    X_train_quantum_30k, X_test_quantum_30k, \n",
    "    y_train_quantum_30k, y_test_quantum_30k,\n",
    "    \"Variational Quantum Classifier\", \"30k\", X_train_quantum_30k.shape[1]\n",
    ")\n",
    "\n",
    "# Quantum 50k\n",
    "print(\"\\n--- Quantum 50k ---\")\n",
    "vqc_50k, y_pred_vqc_50k = train_and_evaluate_vqc(\n",
    "    X_train_quantum_50k, X_test_quantum_50k, \n",
    "    y_train_quantum_50k, y_test_quantum_50k,\n",
    "    \"Variational Quantum Classifier\", \"50k\", X_train_quantum_50k.shape[1]\n",
    ")\n",
    "\n",
    "# Quantum Full\n",
    "print(\"\\n--- Quantum Full ---\")\n",
    "vqc_full, y_pred_vqc_full = train_and_evaluate_vqc(\n",
    "    X_train_quantum, X_test_quantum, \n",
    "    y_train_quantum, y_test_quantum,\n",
    "    \"Variational Quantum Classifier\", \"Full\", X_train_quantum.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a6de3-1701-4e7a-aa84-3c5b3b3181a5",
   "metadata": {},
   "source": [
    "## 4.7 Avaliação do Quantum Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83c3324-0994-471a-8383-188e9bd9c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação da Quantum Neural Network\n",
    "print(\"=\" * 50)\n",
    "print(\"QUANTUM NEURAL NETWORK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Quantum 0k\n",
    "print(\"\\n--- Quantum 0k ---\")\n",
    "qnn_0k, y_pred_qnn_0k = train_and_evaluate_qnn(\n",
    "    X_train_quantum_0k, X_test_quantum_0k, \n",
    "    y_train_quantum_0k, y_test_quantum_0k,\n",
    "    \"Quantum Neural Network\", \"0k\", X_train_quantum_0k.shape[1]\n",
    ")\n",
    "\n",
    "# Quantum 1k\n",
    "print(\"\\n--- Quantum 1k ---\")\n",
    "qnn_1k, y_pred_qnn_1k = train_and_evaluate_qnn(\n",
    "    X_train_quantum_1k, X_test_quantum_1k, \n",
    "    y_train_quantum_1k, y_test_quantum_1k,\n",
    "    \"Quantum Neural Network\", \"1k\", X_train_quantum_1k.shape[1]\n",
    ")\n",
    "\n",
    "# Quantum 10k\n",
    "print(\"\\n--- Quantum 10k ---\")\n",
    "qnn_10k, y_pred_qnn_10k = train_and_evaluate_qnn(\n",
    "    X_train_quantum_10k, X_test_quantum_10k, \n",
    "    y_train_quantum_10k, y_test_quantum_10k,\n",
    "    \"Quantum Neural Network\", \"10k\", X_train_quantum_10k.shape[1]\n",
    ")\n",
    "\n",
    "# Quantum 30k\n",
    "print(\"\\n--- Quantum 30k ---\")\n",
    "qnn_30k, y_pred_qnn_30k = train_and_evaluate_qnn(\n",
    "    X_train_quantum_30k, X_test_quantum_30k, \n",
    "    y_train_quantum_30k, y_test_quantum_30k,\n",
    "    \"Quantum Neural Network\", \"30k\", X_train_quantum_30k.shape[1]\n",
    ")\n",
    "\n",
    "# Quantum 50k\n",
    "print(\"\\n--- Quantum 50k ---\")\n",
    "qnn_50k, y_pred_qnn_50k = train_and_evaluate_qnn(\n",
    "    X_train_quantum_50k, X_test_quantum_50k, \n",
    "    y_train_quantum_50k, y_test_quantum_50k,\n",
    "    \"Quantum Neural Network\", \"50k\", X_train_quantum_50k.shape[1]\n",
    ")\n",
    "\n",
    "# Quantum Full\n",
    "print(\"\\n--- Quantum Full ---\")\n",
    "qnn_full, y_pred_qnn_full = train_and_evaluate_qnn(\n",
    "    X_train_quantum, X_test_quantum, \n",
    "    y_train_quantum, y_test_quantum,\n",
    "    \"Quantum Neural Network\", \"Full\", X_train_quantum.shape[1]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
